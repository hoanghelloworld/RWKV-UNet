{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f943d58b",
   "metadata": {},
   "source": [
    "# RWKV-UNet Training for Custom Segmentation Dataset\n",
    "\n",
    "This notebook demonstrates how to train RWKV-UNet on a custom binary segmentation dataset with the following structure:\n",
    "- train/images (.jpg)\n",
    "- train/masks (.png with 0/255 values)\n",
    "- val/images (.jpg) \n",
    "- val/masks (.png with 0/255 values)\n",
    "- test/images (.jpg, no masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a78ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Import your modules\n",
    "from datasets.dataset_custom import CustomDataset, CustomTransform\n",
    "from utils import DiceLoss, test_single_volume\n",
    "from rwkv_unet import RWKV_UNet\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535218d9",
   "metadata": {},
   "source": [
    "## Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973e9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "class Config:\n",
    "    # Data paths\n",
    "    train_images_dir = \"data/train/images\"\n",
    "    train_masks_dir = \"data/train/masks\"\n",
    "    val_images_dir = \"data/val/images\" \n",
    "    val_masks_dir = \"data/val/masks\"\n",
    "    test_images_dir = \"data/test/images\"\n",
    "    \n",
    "    # Model parameters\n",
    "    img_size = 224\n",
    "    num_classes = 2  # Binary segmentation (background + foreground)\n",
    "    in_channels = 1\n",
    "    \n",
    "    # Training parameters\n",
    "    batch_size = 8\n",
    "    max_epochs = 30\n",
    "    base_lr = 0.001\n",
    "    weight_decay = 0.0001\n",
    "    \n",
    "    # Paths\n",
    "    pretrained_path = 'net_B.pth'  # Path to pretrained encoder weights\n",
    "    output_dir = \"outputs/custom_segmentation\"\n",
    "    predictions_dir = \"predictions/custom_test\"\n",
    "    \n",
    "    # Other\n",
    "    seed = 1234\n",
    "    \n",
    "config = Config()\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "os.makedirs(config.predictions_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33343d5e",
   "metadata": {},
   "source": [
    "## Data Loading and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bea141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "transform = CustomTransform(config.img_size)\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    images_dir=config.train_images_dir,\n",
    "    masks_dir=config.train_masks_dir, \n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    images_dir=config.val_images_dir,\n",
    "    masks_dir=config.val_masks_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = CustomDataset(\n",
    "    images_dir=config.test_images_dir,\n",
    "    is_test=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((config.img_size, config.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ])\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3178ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some training samples\n",
    "def visualize_samples(dataset, num_samples=4):\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        sample = dataset[i]\n",
    "        image = sample['image'].squeeze().cpu().numpy()\n",
    "        mask = sample['label'].cpu().numpy()\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        image = (image + 1) / 2  # From [-1,1] to [0,1]\n",
    "        \n",
    "        axes[0, i].imshow(image, cmap='gray')\n",
    "        axes[0, i].set_title(f'Image {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        axes[1, i].imshow(mask, cmap='gray')\n",
    "        axes[1, i].set_title(f'Mask {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510dd4b9",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7f057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "torch.manual_seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "\n",
    "# Initialize model\n",
    "model = RWKV_UNet(\n",
    "    in_channels=config.in_channels,\n",
    "    num_classes=config.num_classes,\n",
    "    img_size=config.img_size,\n",
    "    pretrained_path=config.pretrained_path\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters())} parameters\")\n",
    "\n",
    "# Loss functions\n",
    "ce_loss = CrossEntropyLoss()\n",
    "dice_loss = DiceLoss(config.num_classes)\n",
    "\n",
    "# Optimizer and scheduler\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config.base_lr, weight_decay=config.weight_decay)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=config.max_epochs, eta_min=0)\n",
    "\n",
    "# TensorBoard logging\n",
    "writer = SummaryWriter(config.output_dir + '/log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278db1f",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90416dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, ce_loss, dice_loss, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        images = batch['image'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss_ce = ce_loss(outputs, labels)\n",
    "        loss_dice = dice_loss(outputs, labels, softmax=True)\n",
    "        loss = 0.3 * loss_ce + 0.7 * loss_dice\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "def validate_epoch(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_dice = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
    "            image = batch['image'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            \n",
    "            # Simple validation without test_single_volume for now\n",
    "            outputs = model(image)\n",
    "            pred = torch.argmax(torch.softmax(outputs, dim=1), dim=1)\n",
    "            \n",
    "            # Calculate Dice score for foreground class\n",
    "            pred_fg = (pred == 1).float()\n",
    "            label_fg = (label == 1).float()\n",
    "            \n",
    "            intersection = torch.sum(pred_fg * label_fg)\n",
    "            union = torch.sum(pred_fg) + torch.sum(label_fg)\n",
    "            \n",
    "            if union > 0:\n",
    "                dice = (2. * intersection / union).item()\n",
    "                total_dice += dice\n",
    "                num_samples += 1\n",
    "    \n",
    "    return total_dice / num_samples if num_samples > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbb0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_dice = 0.0\n",
    "train_losses = []\n",
    "val_dices = []\n",
    "\n",
    "for epoch in range(config.max_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.max_epochs}\")\n",
    "    \n",
    "    # Training\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, ce_loss, dice_loss, device)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    val_dice = validate_epoch(model, val_loader, device)\n",
    "    val_dices.append(val_dice)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Logging\n",
    "    writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "    writer.add_scalar('Dice/Validation', val_dice, epoch)\n",
    "    writer.add_scalar('LR', optimizer.param_groups[0]['lr'], epoch)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Val Dice: {val_dice:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        best_dice = val_dice\n",
    "        best_model_path = os.path.join(config.output_dir, 'best_model.pth')\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved with Dice: {best_dice:.4f}\")\n",
    "    \n",
    "    # Save checkpoint every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        checkpoint_path = os.path.join(config.output_dir, f'epoch_{epoch+1}.pth')\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "# Save final model\n",
    "final_model_path = os.path.join(config.output_dir, 'final_model.pth')\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "\n",
    "print(f\"\\nTraining completed! Best Dice score: {best_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b8bbf",
   "metadata": {},
   "source": [
    "## Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a27bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_dices)\n",
    "plt.title('Validation Dice Score')\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Dice Score')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display some validation predictions\n",
    "def show_predictions(model, dataset, num_samples=4):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(15, 9))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            sample = dataset[i]\n",
    "            image = sample['image'].unsqueeze(0).to(device)\n",
    "            label = sample['label'].numpy()\n",
    "            \n",
    "            output = model(image)\n",
    "            pred = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "            pred = pred.squeeze().cpu().numpy()\n",
    "            \n",
    "            # Denormalize image\n",
    "            img_show = sample['image'].squeeze().numpy()\n",
    "            img_show = (img_show + 1) / 2\n",
    "            \n",
    "            axes[0, i].imshow(img_show, cmap='gray')\n",
    "            axes[0, i].set_title(f'Image {i+1}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(label, cmap='gray')\n",
    "            axes[1, i].set_title(f'Ground Truth {i+1}')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            axes[2, i].imshow(pred, cmap='gray')\n",
    "            axes[2, i].set_title(f'Prediction {i+1}')\n",
    "            axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f597f4",
   "metadata": {},
   "source": [
    "## Test Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33864191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model for testing\n",
    "best_model_path = os.path.join(config.output_dir, 'best_model.pth')\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "print(\"Generating predictions on test data...\")\n",
    "\n",
    "# Create prediction output directory\n",
    "test_predictions_dir = os.path.join(config.predictions_dir, 'masks')\n",
    "os.makedirs(test_predictions_dir, exist_ok=True)\n",
    "\n",
    "# Process test data\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(tqdm(test_loader, desc=\"Predicting\")):\n",
    "        image = batch['image'].to(device)\n",
    "        case_name = batch['case_name'][0]\n",
    "        \n",
    "        # Get prediction\n",
    "        output = model(image)\n",
    "        pred = torch.argmax(torch.softmax(output, dim=1), dim=1)\n",
    "        pred = pred.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Convert prediction to 0/255 format\n",
    "        pred_mask = (pred * 255).astype(np.uint8)\n",
    "        \n",
    "        # Save prediction\n",
    "        output_filename = case_name.replace('.jpg', '.png')\n",
    "        output_path = os.path.join(test_predictions_dir, output_filename)\n",
    "        \n",
    "        # Save as PIL Image\n",
    "        pred_img = Image.fromarray(pred_mask, mode='L')\n",
    "        pred_img.save(output_path)\n",
    "\n",
    "print(f\"Predictions saved to: {test_predictions_dir}\")\n",
    "print(f\"Total predictions generated: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cab39f",
   "metadata": {},
   "source": [
    "## Visualize Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b1736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some test predictions\n",
    "def visualize_test_predictions(num_samples=6):\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(18, 6))\n",
    "    \n",
    "    test_files = os.listdir(config.test_images_dir)[:num_samples]\n",
    "    \n",
    "    for i, filename in enumerate(test_files):\n",
    "        # Load original image\n",
    "        img_path = os.path.join(config.test_images_dir, filename)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load prediction\n",
    "        pred_filename = filename.replace('.jpg', '.png')\n",
    "        pred_path = os.path.join(test_predictions_dir, pred_filename)\n",
    "        if os.path.exists(pred_path):\n",
    "            prediction = Image.open(pred_path).convert('L')\n",
    "            \n",
    "            axes[0, i].imshow(image)\n",
    "            axes[0, i].set_title(f'Test Image {i+1}')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(prediction, cmap='gray')\n",
    "            axes[1, i].set_title(f'Prediction {i+1}')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_test_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9d22b3",
   "metadata": {},
   "source": [
    "## Summary and Results\n",
    "\n",
    "The training is complete! Here's what was accomplished:\n",
    "\n",
    "1. **Data Loading**: Successfully loaded custom dataset with train/val/test splits\n",
    "2. **Model Training**: Trained RWKV-UNet for binary segmentation\n",
    "3. **Validation**: Monitored performance using Dice score\n",
    "4. **Test Prediction**: Generated predictions for all test images\n",
    "5. **Output**: Saved predictions as PNG masks (0/255 format) in the predictions folder\n",
    "\n",
    "### Key Files Generated:\n",
    "- `outputs/custom_segmentation/best_model.pth` - Best performing model\n",
    "- `outputs/custom_segmentation/final_model.pth` - Final model after all epochs\n",
    "- `predictions/custom_test/masks/` - Test predictions folder\n",
    "\n",
    "### Next Steps:\n",
    "- Analyze prediction quality\n",
    "- Fine-tune hyperparameters if needed\n",
    "- Apply post-processing if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d0ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "writer.close()\n",
    "print(\"Training notebook execution completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
